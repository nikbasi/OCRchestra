# ğŸ¯ OMR MASTER PLAN

**Objective**: Build a scalable, high-accuracy OMR system that can process real-world music scores (especially jazz PDFs), handle handwritten-like inputs, and output structured formats like MusicXML or MIDI.

---

## ğŸ§± PHASE 0: Setup & System Design

### ğŸ”§ Step 0.1 â€“ Define Goals
- **Input**: scanned or digital sheet music (PDFs, images)
- **Output**: structured MusicXML or MIDI
- **Capabilities**:
  - Detect symbols (notes, rests, clefs, barlines, etc.)
  - Detect staff structure and layout
  - Infer semantic relationships (pitch, duration, rhythm, articulation)
  - Handle real jazz scores, even noisy or irregular layouts

### ğŸ”§ Step 0.2 â€“ Environment Setup
- Create Python virtual environment
- Install core tools:

```bash
pip install ultralytics opencv-python pillow pdf2image music21
```

- Install MuseScore and ensure CLI works
- Install Label Studio for manual annotation:

```bash
pip install label-studio
```

---

## ğŸ§ª PHASE 1: Synthetic Data Generation (Bootstrapping the Model)

### ğŸ”¹ Step 1.1 â€“ Generate Random Music Snippets
- Use music21 to create simple melodies and chords
- Export as MusicXML

### ğŸ”¹ Step 1.2 â€“ Convert MusicXML to PNG
- Use MuseScore CLI to render:

```bash
musescore -o output.png input.musicxml
```

### ğŸ”¹ Step 1.3 â€“ Generate Ground Truth Labels Automatically
- Use known note positions + clefs from MusicXML
- Create bounding boxes for:
  - Noteheads
  - Clefs
  - Key/time signatures
  - Rests
- Save in YOLOv8 format

### ğŸ”¹ Step 1.4 â€“ Organize Dataset for Training

```bash
dataset/
â”œâ”€â”€ images/train/
â”œâ”€â”€ images/val/
â”œâ”€â”€ labels/train/
â”œâ”€â”€ labels/val/
â””â”€â”€ data.yaml
```

---

## ğŸ§  PHASE 2: First Model â€“ YOLOv8 Symbol Detection

### ğŸ”¹ Step 2.1 â€“ Train YOLOv8 on Synthetic Dataset
- Train initial detector on noteheads, clefs, barlines, etc.
- Evaluate bounding box accuracy on validation set

### ğŸ”¹ Step 2.2 â€“ Export Predictions
- Apply model on:
  - Synthetic validation data
  - Unlabeled real jazz PDFs (converted to images)

---

## ğŸ“– PHASE 3: Real Jazz Book Integration (Human-in-the-Loop Learning)

### ğŸ”¹ Step 3.1 â€“ Prepare Real PDF Data
- Use pdf2image to convert jazz PDFs into PNGs

### ğŸ”¹ Step 3.2 â€“ Run Model on Jazz Pages
- Generate predictions for symbols
- Export to YOLO label format

### ğŸ”¹ Step 3.3 â€“ Correct Model Mistakes
- Import predicted images + labels into Label Studio
- Manually correct bounding boxes + labels
- Export corrected dataset

### ğŸ”¹ Step 3.4 â€“ Retrain Model
- Combine synthetic + corrected jazz labels
- Retrain model with increased diversity
- Evaluate again on real jazz PDFs

---

## ğŸ§© PHASE 4: Staff Detection and Structural Layout

### ğŸ”¹ Step 4.1 â€“ Use OpenCV for Staff Line Detection
- Detect staff lines using morphological filters + projection
- Group lines into staves
- Classify staves as single or grand using:
  - Spacing
  - Clef combination
  - Barlines

### ğŸ”¹ Step 4.2 â€“ Train YOLOv8 for Staff Block Detection (Optional)
- Label full staff regions (bounding boxes)
- Label type (single_staff, grand_staff, etc.)

---

## ğŸ” PHASE 5: Semantic Graph Parsing (Notes to MusicXML)

### ğŸ”¹ Step 5.1 â€“ Build Symbol Graph
- Each detected symbol becomes a node
- Edges = proximity, beams, stems, ties

### ğŸ”¹ Step 5.2 â€“ Infer Pitches
- Use staff position + clef to compute pitch
- Use MusicXML-compatible pitch notation (e.g., `<step>C</step>`)

### ğŸ”¹ Step 5.3 â€“ Infer Durations
- Use symbol type + dots + beaming

### ğŸ”¹ Step 5.4 â€“ Output to MusicXML
- Use music21 to build MusicXML tree
- Export .musicxml or .mid

---

## ğŸŒ PHASE 6: Feedback & Deployment

### ğŸ”¹ Step 6.1 â€“ Streamlit Web Interface
- Upload image
- See predicted symbols overlaid
- Download MusicXML
- Optional: Correct symbols and resubmit

### ğŸ”¹ Step 6.2 â€“ User Correction Loop
- User corrects model output in GUI or Label Studio
- Corrections fed back into training loop

---

## ğŸ§  PHASE 7: Advanced Features (Post-MVP)

- Handwriting adaptation via fine-tuning on MUSCIMA++
- Chord symbol detection (OCR + music context)
- Tuplets and complex rhythms
- Articulations, slurs, dynamics
- Multi-page score stitching
- Ensemble and orchestral layout recognition

---

## âœ… Summary of the Plan

| Phase | Name           | Output                                           |
|-------|----------------|--------------------------------------------------|
| 0     | Setup          | Tools ready (YOLOv8, MuseScore, Label Studio)   |
| 1     | Synthetic Dataset | PNG + YOLO labels for clean music            |
| 2     | First Model    | Trained YOLOv8 to detect musical symbols         |
| 3     | Jazz Books     | Refined model with real scanned scores          |
| 4     | Staff Logic    | Staff blocks, types, and structural layout       |
| 5     | Parsing        | MusicXML reconstruction (notes, rhythms)        |
| 6     | Feedback UI    | Streamlit app + Label Studio review loop        |
| 7     | Advanced       | Handwriting, chords, dynamics, orchestral scores |